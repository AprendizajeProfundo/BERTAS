{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b51d4c2-3e24-4a7f-8257-acbdc6965123",
   "metadata": {
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd24c64-3e9a-4887-9739-42d8796e17c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center>Sentence-Transformers</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e01c6-43e8-4fe4-8b41-da91f83b5577",
   "metadata": {},
   "source": [
    "<center>ploading target data to hdf5 files</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285115a-ff80-4943-9076-81cecef30437",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Autores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51820da-c0e3-4df5-8297-6f2d742b7d8d",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9a186-3466-4d71-99ac-dcda6ddd5e41",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef6d570-6bf9-4285-8ed6-2b728af39c05",
   "metadata": {},
   "source": [
    "1. [Asap++](https://www.cse.iitb.ac.in/~sam/papers/SAM-LREC-2018-ASAP++.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94627548-4158-4901-a5f3-d1cbf7dbca14",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5b782-51c9-4175-8aeb-c2e9da206d46",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee4e4bb-647d-4820-923c-c12e2ce69828",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introduction</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab42dc6-7fc2-4c54-8f2d-b8aab561c5a3",
   "metadata": {},
   "source": [
    "We read the target data Prepared in the Asap++ paper nad upload to the hdf5 files for formats F1, F2 and F8 (Really F8 was porpared by the original authors fo ASAP data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2254769-d728-4aad-bf04-8c1fe08c6d1e",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Load required modules</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd2b4c7-1615-463a-aa86-cd82172902f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f82f2-9b55-4118-aa03-f847a64ce1ad",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Create datasets hdf5 files</span>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01b2833f-dea5-4a05-8e28-f1c84d9e10e9",
   "metadata": {},
   "source": [
    "# filenames\n",
    "file_names_hdf5_ds = ['../Datos/Datasets_hdf5/F1_ds_1783.hdf5',\n",
    "                     '../Datos/Datasets_hdf5/F2_ds_1800.hdf5',\n",
    "                     '../Datos/Datasets_hdf5/F3_ds_1726.hdf5',\n",
    "                     '../Datos/Datasets_hdf5/F4_ds_1772.hdf5',\n",
    "                     '../Datos/Datasets_hdf5/F5_ds_1805.hdf5',\n",
    "                     '../Datos/Datasets_hdf5/F6_ds_1800.hdf5',\n",
    "                     '../Datos/Datasets_hdf5/F7_ds_1569.hdf5',\n",
    "                     '../Datos/Datasets_hdf5/F8_ds_723.hdf5']\n",
    "# create files\n",
    "for file in  file_names_hdf5_ds:\n",
    "    f = h5py.File(file, 'w', userblock_size=512)\n",
    "    with open(file, 'r+') as f1:\n",
    "        doc='This example contains the embeddings of all the essays of an exam type.\\\n",
    "        /nThere are four objects:\\\n",
    "        /essay_id-> It contains the identifier of each essay.\\\n",
    "        /data-> It is an array of size num_total_essays x768 and they correspond to the embeddings \\\n",
    "        of the sentences averaged per essay using the all-mpnet-base-v2 model of sentence transformers.\\\n",
    "        /trait_mean -> It contains the average of the latent traits\\\n",
    "        /global_score -> It contains the original holistic scores/10'\n",
    "        f1.write(doc)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65fdd8e-a1ad-40f0-a40b-4e067a96cf82",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Names of files to process</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae24e212-673a-424a-9d88-332607c45662",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_embeddings_hdf5 = '../Datos/Embeddings_hdf5/'\n",
    "path_target_csv = '../Datos/Clean_data_csv/'\n",
    "path_datsets_hdf5 = '../Datos/Datasets_hdf5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6950e4cf-6f1a-4fc3-a6d6-d89d5185c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_embeddings_hdf5 = sorted(glob(f'{path_embeddings_hdf5}F*'))\n",
    "file_names_target_csv = sorted(glob(f'{path_target_csv}F*'))\n",
    "file_names_datasets_hdf5 = sorted(glob(f'{path_datsets_hdf5}F*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa87e52-50fb-48a3-886c-6850c3cf13e3",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Create dataset hdf5</span>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06928239-cff3-43e3-99d0-272c84444685",
   "metadata": {},
   "source": [
    "# Narrative/persuasive\n",
    "col_names = ['Content', 'Organization', 'Word_Choice', 'Fluency', 'Conventions']\n",
    "\n",
    "\n",
    "# files 1 and 2\n",
    "for file_hdf5_emb, file_hdf5_ds, file_target in \\\n",
    "    zip(file_names_embeddings_hdf5[:2], file_names_datasets_hdf5[:2], file_names_target_csv[:2]):\n",
    "    \n",
    "    fe = h5py.File(file_hdf5_emb,'r')\n",
    "    fd = h5py.File(file_hdf5_ds,'r+')\n",
    "    fp = pd.read_csv(file_target)\n",
    "    \n",
    "    fp_values = np.array(fp[col_names].values, dtype=np.float32)\n",
    "    trait_mean = np.mean(fp_values, axis=1, dtype=np.float32)[:, np.newaxis]\n",
    "    global_score = np.array(fp['global_score'].values/10.0, dtype=np.float32)[:, np.newaxis]\n",
    "    dataset_emb = fe['data']\n",
    "    \n",
    "    fd['data'] = dataset_emb[...]\n",
    "    fd['target'] = fp_values\n",
    "    fd['trait_mean'] = trait_mean\n",
    "    fd['global_score'] = global_score\n",
    "    \n",
    "    fe.close()\n",
    "    fd.close()\n",
    "\n",
    "    # files 7 and 8\n",
    "for file_hdf5_emb, file_hdf5_ds, file_target in \\\n",
    "    zip(file_names_embeddings_hdf5[6:], file_names_datasets_hdf5[6:], file_names_target_csv[6:]):\n",
    "    \n",
    "    fe = h5py.File(file_hdf5_emb,'r')\n",
    "    fd = h5py.File(file_hdf5_ds,'r+')\n",
    "    fp = pd.read_csv(file_target)\n",
    "    \n",
    "    fp_values = np.array(fp[col_names].values, dtype=np.float32)\n",
    "    trait_mean = np.mean(fp_values, axis=1, dtype=np.float32)[:, np.newaxis]\n",
    "    global_score = np.array(fp['global_score'].values/10.0, dtype=np.float32)[:, np.newaxis]\n",
    "    dataset_emb = fe['data']\n",
    "    \n",
    "    fd['data'] = dataset_emb[...]\n",
    "    fd['target'] = fp_values\n",
    "    fd['trait_mean'] = trait_mean\n",
    "    fd['global_score'] = global_score\n",
    "    \n",
    "    fe.close()\n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5444aca4-311e-40d2-bd2b-88977e510eac",
   "metadata": {},
   "source": [
    "# Dependent\n",
    "col_names = ['Content', 'Prompt_Adherence', 'Language', 'Narrativity']\n",
    "\n",
    "# files 3, 4, 5, y 6\n",
    "for file_hdf5_emb, file_hdf5_ds, file_target in \\\n",
    "    zip(file_names_embeddings_hdf5[2:6], file_names_datasets_hdf5[2:6], file_names_target_csv[2:6]):\n",
    "    \n",
    "    fe = h5py.File(file_hdf5_emb,'r')\n",
    "    fd = h5py.File(file_hdf5_ds,'r+')\n",
    "    fp = pd.read_csv(file_target)\n",
    "    \n",
    "    fp_values = np.array(fp[col_names].values, dtype=np.float32)\n",
    "    trait_mean = np.mean(fp_values, axis=1, dtype=np.float32)[:, np.newaxis]\n",
    "    global_score = np.array(fp['global_score'].values/10.0, dtype=np.float32)[:, np.newaxis]\n",
    "    dataset_emb = fe['data']\n",
    "    \n",
    "    fd['/data'] = dataset_emb[...]\n",
    "    fd['/target'] = fp_values\n",
    "    fd['/trait_mean'] = trait_mean\n",
    "    fd['/global_score'] = global_score\n",
    "    \n",
    "    fe.close()\n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828c79e-28aa-4000-b028-4b56c29fd116",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96bacf94-ae80-4d82-8165-0fa742187108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0 data shape: <HDF5 dataset \"data\": shape (1783, 768), type \"<f4\">\n",
      "f0 target shape: <HDF5 dataset \"target\": shape (1783, 5), type \"<f4\">\n",
      "f0 trait_mean shape: <HDF5 dataset \"trait_mean\": shape (1783, 1), type \"<f4\">\n",
      "f0 global_score shape: <HDF5 dataset \"global_score\": shape (1783, 1), type \"<f4\">\n",
      "f1 data shape: <HDF5 dataset \"data\": shape (1800, 768), type \"<f4\">\n",
      "f1 target shape: <HDF5 dataset \"target\": shape (1800, 5), type \"<f4\">\n",
      "f1 trait_mean shape: <HDF5 dataset \"trait_mean\": shape (1800, 1), type \"<f4\">\n",
      "f1 global_score shape: <HDF5 dataset \"global_score\": shape (1800, 1), type \"<f4\">\n",
      "f2 data shape: <HDF5 dataset \"data\": shape (1726, 768), type \"<f4\">\n",
      "f2 target shape: <HDF5 dataset \"target\": shape (1726, 4), type \"<f4\">\n",
      "f2 trait_mean shape: <HDF5 dataset \"trait_mean\": shape (1726, 1), type \"<f4\">\n",
      "f2 global_score shape: <HDF5 dataset \"global_score\": shape (1726, 1), type \"<f4\">\n",
      "f3 data shape: <HDF5 dataset \"data\": shape (1772, 768), type \"<f4\">\n",
      "f3 target shape: <HDF5 dataset \"target\": shape (1772, 4), type \"<f4\">\n",
      "f3 trait_mean shape: <HDF5 dataset \"trait_mean\": shape (1772, 1), type \"<f4\">\n",
      "f3 global_score shape: <HDF5 dataset \"global_score\": shape (1772, 1), type \"<f4\">\n",
      "f4 data shape: <HDF5 dataset \"data\": shape (1805, 768), type \"<f4\">\n",
      "f4 target shape: <HDF5 dataset \"target\": shape (1805, 4), type \"<f4\">\n",
      "f4 trait_mean shape: <HDF5 dataset \"trait_mean\": shape (1805, 1), type \"<f4\">\n",
      "f4 global_score shape: <HDF5 dataset \"global_score\": shape (1805, 1), type \"<f4\">\n",
      "f5 data shape: <HDF5 dataset \"data\": shape (1800, 768), type \"<f4\">\n",
      "f5 target shape: <HDF5 dataset \"target\": shape (1800, 4), type \"<f4\">\n",
      "f5 trait_mean shape: <HDF5 dataset \"trait_mean\": shape (1800, 1), type \"<f4\">\n",
      "f5 global_score shape: <HDF5 dataset \"global_score\": shape (1800, 1), type \"<f4\">\n",
      "f6 data shape: <HDF5 dataset \"data\": shape (1569, 768), type \"<f4\">\n",
      "f6 target shape: <HDF5 dataset \"target\": shape (1569, 5), type \"<f4\">\n",
      "f6 trait_mean shape: <HDF5 dataset \"trait_mean\": shape (1569, 1), type \"<f4\">\n",
      "f6 global_score shape: <HDF5 dataset \"global_score\": shape (1569, 1), type \"<f4\">\n",
      "f7 data shape: <HDF5 dataset \"data\": shape (723, 768), type \"<f4\">\n",
      "f7 target shape: <HDF5 dataset \"target\": shape (723, 5), type \"<f4\">\n",
      "f7 trait_mean shape: <HDF5 dataset \"trait_mean\": shape (723, 1), type \"<f4\">\n",
      "f7 global_score shape: <HDF5 dataset \"global_score\": shape (723, 1), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "## Sanity check\n",
    "for i, file in enumerate(file_names_datasets_hdf5):\n",
    "    f = h5py.File(file,'r')\n",
    "    print(f'f{i} data shape:',f['data'])\n",
    "    print(f'f{i} target shape:',f['target'])\n",
    "    print(f'f{i} trait_mean shape:',f['trait_mean'])\n",
    "    print(f'f{i} global_score shape:',f['global_score'])    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaa339-fd6a-497a-a962-8bc6f1a258d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
